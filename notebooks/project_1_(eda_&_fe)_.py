# -*- coding: utf-8 -*-
"""Project 1 (EDA & FE) .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RMJUW4xSLbJdZZrjQC_J2D_ItlBx2u-U
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

dataset=pd.read_csv('Algerian_forest_fires_dataset.csv')

dataset.head()

dataset.info()

"""**Data Cleaning**"""

## Missing values
dataset[dataset.isnull().any(axis=1)]

"""The dataset is converted into two sets based on Region from 122th index, we can make a new column based on the Region

1. "Bejaia Region Dataset"
2. "Sidi-Bel Abbes Region Dataset"

Add new column with region
"""

dataset.loc[:122,'Region']=0
dataset.loc[122:,'Region']=1
df=dataset

df.info()

df.head()

df[['Region']]=df[['Region']].astype(int)

df.head()

df.isnull().sum()

## Removing the null values
df=df.dropna().reset_index(drop=True)

df.head()

df.isnull().sum()

df.iloc[[122]]

## Remove the 122nd row
df=df.drop(122).reset_index(drop=True)

df.iloc[[122]]

df.columns

## Fix spaces in columns names
df.columns=df.columns.str.strip()
df.columns

df.info()

"""Change the required columns as integer data type"""

df.columns

# Fix spaces in columns names and change the required columns as integer data type in the same cell
#df.columns = df.columns.str.strip()
df[['month', 'day', 'year', 'Temperature', 'RH', 'Ws']] = df[['month', 'day', 'year', 'Temperature', 'RH', 'Ws']].astype(int)

df.info()

"""Changing the other columns to float datatype"""

objects=[features for features in df.columns if df[features].dtypes=='O']

objects

for i in objects:
  if i!='Classes':
    df[i]=df[i].astype(float)

df.info()

objects

df.describe()

df.head()

## Let save the cleaned dataset
df.to_csv('Algerian_forest_fires_cleaned_dataset_new.csv',index=False)

"""**Exploratory Data Analysis**"""

## drop day,month & year
df_copy=df.drop(['day','month','year'],axis=1)

df_copy.head()

## categories in classes
df_copy['Classes'].value_counts()

# Encoding of the categories in classes
df_copy['Classes']=np.where(df_copy['Classes'].str.contains('not fire'),0,1)

df_copy.head()

df_copy.tail()

df_copy['Classes'].value_counts()

# Plot density plot for all features
import seaborn as sns
sns.set_style('darkgrid')

#plt.style.use('seaborn')
df_copy.hist(bins=50,figsize=(20,15))
plt.show()

## Percentage for Pie Chart
Percentage=df_copy['Classes'].value_counts(normalize=True)*100

## plotting piechart
classlabels=["Fire","Not Fire"]
plt.figure(figsize=(12,7))
plt.pie(Percentage,labels=classlabels,autopct='%1.2f%%')
plt.title('Pie Chart for Classes')
plt.show()

"""Correlation"""

df_copy.corr()

sns.heatmap(df_copy.corr(), annot=True)

## Box Plots
sns.boxplot(df['FWI'],color='green')

df['Classes']=np.where(df['Classes'].str.contains('not fire'), 'not fire', 'fire')

## Monthly Fire Analysis
dftemp = df.loc[df['Region']==1]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month',hue='Classes',data=df)
plt.ylabel('Number of Fires',weight=bold)
plt.xlabel('Months',weight='bold')
plt.title('Fire Analysis of Sidi-Bel Regions',weight='bold')
plt.show()

dftemp = df.loc[df['Region']==0]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month',hue='Classes',data=df)
plt.ylabel('Number of Fires',weight=bold)
plt.xlabel('Months',weight='bold')
plt.title('Fire Analysis of Sidi-Bel Regions',weight='bold')
plt.show()

"""Its observed that August & September had the most no. of forest fires for both regions.And from the above plot of months, we can understand few things

Most of the fires happened in August & very high fires happened in only 3 months- June, July & August

Less fires was on September

**Model Training**
"""

df=pd.read_csv('Algerian_forest_fires_cleaned_dataset_new.csv')

df.head()

## drop day, month & year
df.drop(['day','month','year'],axis=1,inplace=True)

df.head()

df['Classes'].value_counts()

## Encoding
df['Classes'] = np.where(df['Classes'].str.contains('not fire'),0,1)

df.tail()

df['Classes'].value_counts()

## Independent & dependent features
X=df.drop('FWI',axis=1)
y=df['FWI']

X.head()

y

## Train Test split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

X_train.shape,X_test.shape

## Feature Selection based on correlation
X_train.corr()

## Check for multicollinearity
plt.figure(figsize=(12,10))
corr = X_train.corr()
sns.heatmap(corr,annot=True)

def correlation(dataset, threshold):
  col_corr = set()
  corr_matrix = dataset.corr()
  for i in range(len(corr_matrix.columns)):
    for j in range(i):
      if abs(corr_matrix.iloc[i,j]) > threshold:
        colname = corr_matrix.columns[i]
        col_corr.add(colname)
  return col_corr

## threshold--Domain expertise
corr_features = correlation(X_train,0.85)

corr_features

## drop features when correlation is more than 0.85
X_train.drop(corr_features,axis=1,inplace=True)
X_test.drop(corr_features,axis=1,inplace=True)
X_train.shape,X_test.shape

"""Feature Scaling or Standardization"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled

"""Box Plots to understand Effect of Standard Scaler"""

plt.subplots(figsize=(15,5))
plt.subplot(1,2,1)
sns.boxplot(data=X_train)
plt.title('X_train Before Scaling')
plt.subplot(1,2,2)
sns.boxplot(data=X_train_scaled)
plt.title('X_train After Scaling')
plt.show()

"""Linear Regression Model"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
linreg=LinearRegression()
linreg.fit(X_train_scaled,y_train)
y_pred=linreg.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)
plt.scatter(y_test,y_pred)

"""Lasso Regression

"""

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
lasso=Lasso()
lasso.fit(X_train_scaled,y_train)
y_pred=lasso.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)
plt.scatter(y_test,y_pred)

"""Cross Validation Lasso"""

from sklearn.linear_model import LassoCV
lassocv = LassoCV(cv=5)
lassocv.fit(X_train_scaled,y_train)

lassocv.alpha_

lassocv.alphas_

y_pred=lassocv.predict(X_test_scaled)
plt.scatter(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)

"""Ridge Regression Model"""

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
ridge=Ridge()
ridge.fit(X_train_scaled,y_train)
y_pred=ridge.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)
plt.scatter(y_test,y_pred)

from sklearn.linear_model import RidgeCV
ridgecv = RidgeCV(cv=5)
ridgecv.fit(X_train_scaled,y_train)
y_pred=ridgecv.predict(X_test_scaled)
plt.scatter(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)

ridgecv.get_params()

"""Elastic Net Regression"""

from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
elasticnet=ElasticNet()
elasticnet.fit(X_train_scaled,y_train)
y_pred=elasticnet.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)
plt.scatter(y_test,y_pred)

from sklearn.linear_model import ElasticNetCV
elasticnetcv = ElasticNetCV(cv=5)
elasticnetcv.fit(X_train_scaled,y_train)
y_pred=elasticnetcv.predict(X_test_scaled)
plt.scatter(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print('Mean absolute error:',mae)
print('R2 Score:',score)

## Pickle the machine learning models, preprocessing model standardscaler
scaler

ridge

import pickle
pickle.dump(scaler,open('scaler.pkl','wb'))
pickle.dump(ridge,open('ridge.pkl','wb'))

